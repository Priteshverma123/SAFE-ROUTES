{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f48fd2",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "949abdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Libraries needed for NLP \n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer # used to reduce words to their base form, also known as the root form.\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "985005f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed for Tensorflow processing \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc060c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the intents.json file from your local device \n",
    "with open('chat.json') as json_data :\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0023c46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'greeting',\n",
       "   'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day'],\n",
       "   'responses': ['Hello, thanks for visiting',\n",
       "    'Good to see you again',\n",
       "    'Hi there, how can I help?']},\n",
       "  {'tag': 'goodbye',\n",
       "   'patterns': ['Bye', 'See you later', 'Goodbye'],\n",
       "   'responses': ['See you later, thanks for visiting',\n",
       "    'Have a nice day',\n",
       "    'Bye! Come back again soon.']},\n",
       "  {'tag': 'thanks',\n",
       "   'patterns': ['Thanks', 'Thank you', \"That's helpful\"],\n",
       "   'responses': ['Happy to help!', 'Any time!', 'My pleasure']},\n",
       "  {'tag': 'chatbot',\n",
       "   'patterns': ['Who built this chatbot?',\n",
       "    'Tell me about Chatbot',\n",
       "    'What is this chatbot name?'],\n",
       "   'responses': ['Hi, I am ORIGIN designed by Vigilance.',\n",
       "    'Thanks for asking. I am designed by Vigilance.',\n",
       "    'I am a ORIGIN powered by .EXE DEVELOPERS.']},\n",
       "  {'tag': 'location',\n",
       "   'patterns': ['What is the nearest police station location?',\n",
       "    'Where is nearest police station located?',\n",
       "    'What is the nearest help centre address?'],\n",
       "   'responses': ['can you tell me your road name.',\n",
       "    'please enter your road name, so that i can help you further!',\n",
       "    'I would love to help you, can you please enter your road name?']},\n",
       "  {'tag': 'Aarey road goregaon',\n",
       "   'patterns': ['i am at aarey road goregaon',\n",
       "    'Aarey road',\n",
       "    'currently at aarey road goregaon',\n",
       "    'arey road'],\n",
       "   'responses': ['Vanrai Police station, phone no.:022 2686 1677 ']},\n",
       "  {'tag': 'Arun Kumar Vaidya Marg',\n",
       "   'patterns': ['i am at arun kumar vaidya marg',\n",
       "    'Arun kumar vaidya marg',\n",
       "    'currently at arun kumar vaidya marg goregaon',\n",
       "    'arun kumar road'],\n",
       "   'responses': ['gokuldham Police chowki (approx 0km away), phone no.: 06864 639 423 ']},\n",
       "  {'tag': 'Mohan Gokhale Road',\n",
       "   'patterns': ['i am at mohan gokhale road',\n",
       "    'mohan gokhale road',\n",
       "    'currently at mohan gokhale road goregaon',\n",
       "    'mohan gokhale road'],\n",
       "   'responses': ['Aarey Police station, phone no.: 022 2927 2485']},\n",
       "  {'tag': 'Yashodham Vidyal Marg',\n",
       "   'patterns': ['i am at Yashodham Vidyal marg',\n",
       "    'Yashodham Vidyal marg',\n",
       "    'currently at Yashodham Vidyal marg goregaon',\n",
       "    'Yashodham Vidyal road'],\n",
       "   'responses': ['gokuldham Police chowki (approx 0km away), phone no.: 06864 639 423']},\n",
       "  {'tag': 'Kanyapada road',\n",
       "   'patterns': ['i am at kanyapada',\n",
       "    'kanyapada rd',\n",
       "    'currently at kanyapada goregaon',\n",
       "    'kanyapada road'],\n",
       "   'responses': ['gokuldham Police chowki (approx 0km away), phone no.: 06864 639 423']},\n",
       "  {'tag': 'Krishna Vatika Marg',\n",
       "   'patterns': ['i am at krishna vatika marg',\n",
       "    'krishna vatika marg',\n",
       "    'currently at krishna vatika marg goregaon',\n",
       "    'krishna vatika road'],\n",
       "   'responses': ['gokuldham Police chowki (approx 0km away), phone no.: 06864 639 423']},\n",
       "  {'tag': 'Sai Road gokuldham',\n",
       "   'patterns': ['i am at Gokuldham',\n",
       "    'sai road gokuldham',\n",
       "    'currently at gokuldham colony goregaon',\n",
       "    'sai road goregaon(east)'],\n",
       "   'responses': ['gokuldham Police chowki (approx 0km away), phone no.: 06864 639 423']},\n",
       "  {'tag': 'Film City Road',\n",
       "   'patterns': ['i am at film city',\n",
       "    'film city',\n",
       "    'currently at film city road goregaon',\n",
       "    'film city road'],\n",
       "   'responses': ['Hanuman nagar  (approx 0km away)']},\n",
       "  {'tag': 'NNP',\n",
       "   'patterns': ['i am at NNP', 'NNP road', 'currently at nnp goregaon', 'nnp'],\n",
       "   'responses': ['Hanumar nagar police station (approx 0km away)']},\n",
       "  {'tag': 'SV road Goregaon west',\n",
       "   'patterns': ['i am at SV road goregaon west',\n",
       "    'sv road goregaon',\n",
       "    'currently at sv road goregaon west',\n",
       "    'sv road'],\n",
       "   'responses': ['Goregaon Police station (approx 1km away), phone no.: 022 2872 3252']},\n",
       "  {'tag': 'Kamu BaBa Road goregaon',\n",
       "   'patterns': ['i am at kamu baba road',\n",
       "    'kamu baba road ',\n",
       "    'currently at kamu baba road  goregaon west',\n",
       "    'goregaon west'],\n",
       "   'responses': ['Goregaon Police station (approx 1km away), phone no.: 022 2872 3252']},\n",
       "  {'tag': 'Unnat Nagar Road no. 1',\n",
       "   'patterns': ['i am at unnat nagar road no. 1',\n",
       "    'unnat nagar road',\n",
       "    'currently at unnat nagar goregaon',\n",
       "    'unnat rd no. 1'],\n",
       "   'responses': ['Goregaon Poloce Chowki']},\n",
       "  {'tag': 'Unnat Nagar Road no. 2',\n",
       "   'patterns': ['i am at unnat nagar no. 2',\n",
       "    'unnat nagar road',\n",
       "    'currently at unnat nagar road 2 goregaon',\n",
       "    'unnat nagar'],\n",
       "   'responses': ['Goregaon Police chowki']},\n",
       "  {'tag': 'Sitaram Patkar Road ',\n",
       "   'patterns': ['i am at sitaram patkar road ',\n",
       "    'patlar road',\n",
       "    'currently at sitaram patkar road goregaon',\n",
       "    'patkar road'],\n",
       "   'responses': ['Goregaon west police stattion, phone no.: 022 2872 3252']},\n",
       "  {'tag': 'Gaiwadi Road',\n",
       "   'patterns': ['i am at gaiwadi road',\n",
       "    'gaiwadi road',\n",
       "    'currently at gaiwadiu road goregaon',\n",
       "    'gaiwadi rd goregaon west'],\n",
       "   'responses': ['Goregaon west police stattion, phone no.: 022 2872 3252']},\n",
       "  {'tag': 'Raheja Marg ',\n",
       "   'patterns': ['i am at raheja',\n",
       "    'raheja road',\n",
       "    'currently at raheja  goregaon',\n",
       "    'rhaeja heights'],\n",
       "   'responses': ['Gokuldham police chawki(approx 1km), phone no.: 06864 639 423']},\n",
       "  {'tag': 'Westin Garden Road',\n",
       "   'patterns': ['i am at westin road',\n",
       "    'westin garden road',\n",
       "    'currently at westin hotel goregaon',\n",
       "    'westin goregaon'],\n",
       "   'responses': ['Aarey Police station, phone no.: 022 2927 2485']},\n",
       "  {'tag': 'help centre',\n",
       "   'patterns': ['women helpline number', 'helpline', 'women safety number '],\n",
       "   'responses': ['022 2659 2707', '022 2266 2013', '082911 35660']},\n",
       "  {'tag': 'about',\n",
       "   'patterns': ['Who are you?', 'Tell me about Yourself', 'What is this?'],\n",
       "   'responses': ['I am a AI chatbot named  as ORIGIN developed by Vigilance.',\n",
       "    'We are few passionate developers named as .EXE DEVELOPERS.']},\n",
       "  {'tag': 'error',\n",
       "   'patterns': ['asmsmsbcjsnasb',\n",
       "    'w132134tjti8wrf',\n",
       "    'say something dsfyefuhf'],\n",
       "   'responses': [\"Invalid syntax, sorry but I couldn't understand.\"]}]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb585fa6",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING THE TEXT DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b380600",
   "metadata": {},
   "outputs": [],
   "source": [
    "words =[]   # will contain all the unique words from the pattern to be trained so that chatbot gives correct outcome  \n",
    "classes =[]   # it will contain the list of all the text totally 8 elements here in text, so it will contain totally 8 elements in the document\n",
    "documents =[] # documents is like a tuple which will contain the first list , the first element of the list of words \n",
    "ignore =['?'] # if you want to remove any special characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a9a74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each sentence in the intents patterns\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each and every word in the sentence\n",
    "        w =nltk.word_tokenize(pattern)\n",
    "        # add words to the words list \n",
    "        words.extend(w)\n",
    "        # add words to documents \n",
    "        documents.append((w,intent['tag']))\n",
    "        # add tags to our classes list \n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9ee438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 documents\n",
      "25 classes ['Aarey road goregaon', 'Arun Kumar Vaidya Marg', 'Film City Road', 'Gaiwadi Road', 'Kamu BaBa Road goregaon', 'Kanyapada road', 'Krishna Vatika Marg', 'Mohan Gokhale Road', 'NNP', 'Raheja Marg ', 'SV road Goregaon west', 'Sai Road gokuldham', 'Sitaram Patkar Road ', 'Unnat Nagar Road no. 1', 'Unnat Nagar Road no. 2', 'Westin Garden Road', 'Yashodham Vidyal Marg', 'about', 'chatbot', 'error', 'goodbye', 'greeting', 'help centre', 'location', 'thanks']\n",
      "95 unique stemmed words [\"'s\", '(', ')', '.', '1', '2', 'aarey', 'about', 'address', 'am', 'anyon', 'are', 'arey', 'arun', 'asmsmsbcjsnasb', 'at', 'baba', 'built', 'bye', 'centr', 'chatbot', 'citi', 'coloni', 'current', 'day', 'dsfyefuhf', 'east', 'film', 'gaiwadi', 'gaiwadiu', 'garden', 'gokhal', 'gokuldham', 'good', 'goodby', 'goregaon', 'height', 'hello', 'help', 'helplin', 'hi', 'hotel', 'how', 'i', 'is', 'kamu', 'kanyapada', 'krishna', 'kumar', 'later', 'locat', 'marg', 'me', 'mohan', 'nagar', 'name', 'nearest', 'nnp', 'no', 'number', 'patkar', 'patlar', 'polic', 'raheja', 'rd', 'rhaeja', 'road', 'safeti', 'sai', 'say', 'see', 'sitaram', 'someth', 'station', 'sv', 'tell', 'thank', 'that', 'the', 'there', 'thi', 'unnat', 'vaidya', 'vatika', 'vidyal', 'w132134tjti8wrf', 'west', 'westin', 'what', 'where', 'who', 'women', 'yashodham', 'you', 'yourself']\n"
     ]
    }
   ],
   "source": [
    "# Perform stemming and lower each word as well as remove duplicates\n",
    "words =[stemmer.stem(w.lower()) for w in words if w not in ignore] # stemmer converts the word into its root word\n",
    "words = sorted(list(set(words))) # coverted so that no duplicated or same words are appended in the list \n",
    "\n",
    "# remove duplicate classes \n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print(len(documents),\"documents\")\n",
    "print(len(classes),\"classes\",classes)\n",
    "print(len(words),\"unique stemmed words\",words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29dfaff",
   "metadata": {},
   "source": [
    "#  CREATING AND TRAINING THE MODEL FOR CHATBOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "965daad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_16912\\1158850164.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  training = np.array(training)\n"
     ]
    }
   ],
   "source": [
    "# creating training data \n",
    "training =[]   # will work as X data \n",
    "output =[]   # will work as Y data\n",
    "# create an empty array for output\n",
    "output_empty =[0]* len(classes)\n",
    "\n",
    "# creating training set ,bag of words for each sentence \n",
    "for doc in documents:\n",
    "    # initialize bag of words \n",
    "    bag =[]\n",
    "    # list of tokenized words for the pattern \n",
    "    pattern_words =doc[0]\n",
    "    # stemming each word \n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    # create a bag of words of array \n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    # output is '1' for current tag and '0' for the rest of other tags \n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])]=1\n",
    "    \n",
    "    training.append([bag,output_row])\n",
    "# shuffling features and turning it to np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# creating training lists\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18f3bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10,input_shape=(len(train_x[0]),))) # 1st layer with 10m neurons\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.add(tf.keras.layers.Dense(len(train_y[0]),activation='softmax')) # when there is more than 2 class(multi class classification) softmax is used\n",
    "model.compile(tf.keras.optimizers.Adam(),loss='categorical_crossentropy',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52fdddf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 3ms/step - loss: 3.2472 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.2107 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.1812 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1508 - accuracy: 0.0426\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.1199 - accuracy: 0.0851\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.0901 - accuracy: 0.1383\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.0583 - accuracy: 0.1809\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 3.0255 - accuracy: 0.2234\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.9908 - accuracy: 0.2553\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.9541 - accuracy: 0.2872\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.9156 - accuracy: 0.2979\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.8745 - accuracy: 0.3404\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.8296 - accuracy: 0.3617\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.7840 - accuracy: 0.3723\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.7333 - accuracy: 0.3936\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.6812 - accuracy: 0.4362\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.6254 - accuracy: 0.4681\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.5684 - accuracy: 0.4787\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.5060 - accuracy: 0.4894\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.4434 - accuracy: 0.4894\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.3777 - accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.3098 - accuracy: 0.5319\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.2412 - accuracy: 0.5638\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.1719 - accuracy: 0.5957\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.1015 - accuracy: 0.6277\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 2.0320 - accuracy: 0.6383\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9595 - accuracy: 0.6915\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.8896 - accuracy: 0.6915\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.8196 - accuracy: 0.7021\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.7519 - accuracy: 0.7234\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.6845 - accuracy: 0.7553\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.6184 - accuracy: 0.7660\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.5536 - accuracy: 0.7766\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.4911 - accuracy: 0.8191\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.4280 - accuracy: 0.8511\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.3692 - accuracy: 0.8511\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.3127 - accuracy: 0.8617\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.2568 - accuracy: 0.8830\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.2012 - accuracy: 0.9149\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.1497 - accuracy: 0.9149\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.1000 - accuracy: 0.9468\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.0512 - accuracy: 0.9468\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0051 - accuracy: 0.9468\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.9592 - accuracy: 0.9468\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.9171 - accuracy: 0.9468\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.8737 - accuracy: 0.9574\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.8349 - accuracy: 0.9574\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7974 - accuracy: 0.9574\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7591 - accuracy: 0.9574\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7247 - accuracy: 0.9574\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.9681\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.9681\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.9681\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5986 - accuracy: 0.9681\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.9787\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.9787\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.9894\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.9894\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.9894\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.9894\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.9894\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.9894\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.9894\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.9894\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.9894\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.9894\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.9894\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.9894\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.9894\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2843 - accuracy: 0.9894\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.9894\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2614 - accuracy: 0.9894\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.9894\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9894\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.9894\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2217 - accuracy: 0.9894\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9894\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2049 - accuracy: 0.9894\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9894\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9894\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9894\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9894\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9894\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.9894\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9894\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9894\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9894\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9894\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9894\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9894\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9894\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9894\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9894\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9894\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9894\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9894\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9894\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.9894\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9894\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.pkl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.pkl\\assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(train_x),np.array(train_y),epochs=100,batch_size=8,verbose=1)\n",
    "model.save(\"model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59cec8",
   "metadata": {},
   "source": [
    "# MAKING PREDICTIONS USING CHATBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "755f8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle.dump({\"words\":words,'classes':classes},open(\"training_data\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b05cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75174900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restoring all the data structures \n",
    "data = pickle.load(open(\"training_data\",\"rb\"))\n",
    "words = data['words']\n",
    "classes = data['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0447b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('chat.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0c5df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenizing the pattern\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stemming each word \n",
    "    sentence_words =[stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# returning bag of words array :0 or 1 for each word in the bag that exists in the sentence \n",
    "def bow(sentence,words):\n",
    "    # tokenize the pattern \n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # generating bag of words \n",
    "    bag = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w==s:\n",
    "                bag[i]=1\n",
    "    bag = np.array(bag)\n",
    "    return(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d25a67ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_THRESHOLD =0.30\n",
    "def classify(sentence):\n",
    "    # generate probabilities from the mmodel \n",
    "    bag = bow(sentence,words)\n",
    "    results = model.predict(np.array([bag]))\n",
    "    # filter out predictions below a threshold \n",
    "    results =[[i,r] for i ,r in enumerate(results[0]) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probabilty \n",
    "    results.sort(key=lambda x:x[1],reverse=True)\n",
    "    return_list =[]\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]],r[1]))\n",
    "    # return tuple of intent and probablity \n",
    "    return return_list\n",
    "\n",
    "def response(sentence):\n",
    "    results = classify(sentence)\n",
    "    # if we have a classification then find the matching intent tag \n",
    "    if results:\n",
    "        # loop as long as there are matches to the process \n",
    "        while results:\n",
    "            for i in intents['intents']:\n",
    "                # find a tag matching the first result\n",
    "                if i['tag']== results[0][0]:\n",
    "                    # a random response from the intent \n",
    "                    return print(random.choice(i['responses']))\n",
    "              \n",
    "            results.pop(0)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d14f15e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "Hello, thanks for visiting\n"
     ]
    }
   ],
   "source": [
    "response(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "121e920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "can you tell me your road name.\n"
     ]
    }
   ],
   "source": [
    "response('Where is the nearest police station located')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8df5fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "Vanrai Police station, phone no.:022 2686 1677 \n"
     ]
    }
   ],
   "source": [
    "response(\"aarey road\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23c77d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "can you tell me your road name.\n"
     ]
    }
   ],
   "source": [
    "response('WhAT is the nearest help centre address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2739db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "gokuldham Police chowki (approx 0km away), phone no.: 06864 639 423\n"
     ]
    }
   ],
   "source": [
    "response('YAshodham vidyal marg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d1ceb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "gokuldham Police chowki (approx 0km away), phone no.: 06864 639 423\n"
     ]
    }
   ],
   "source": [
    "response(\"kanyapada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae015851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "Hanuman nagar  (approx 0km away)\n"
     ]
    }
   ],
   "source": [
    "response(\"film city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4d7b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"film city\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "26fe23d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "Hanuman nagar  (approx 0km away)\n"
     ]
    }
   ],
   "source": [
    "response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373726a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
